*Check out the preprint for our overview paper on [adaptation algorithms for speech recognition](https://arxiv.org/pdf/2008.06580.pdf).*

I am currently working within the [Machine Learning Center of Excellence] at J.P. Morgan Chase.

I recently finished my PhD studies within the [ILCC] and [CSTR] institutes of the [School of Informatics] at the [University of Edinburgh] under the supervision of [Steve Renals] and [Peter Bell]. There I worked on acoustic models for automatic speech recognition, but I'm also keenly interested in other aspects of audio processing (music information retrieval) or human perception (computational auditory scene analysis).

### Past
- PhD student at [CSTR] working on automatic speech recognition
- Interned at [Bloomberg]
- Interned at [Sonos] in the Advanced Technology team, supervised by [Daniele Giacobello]
- Collected the [Self-dialogue Corpus] as part of team [Edina] in the [Amazon Alexa Prize]
- Built a [sound shredder](https://www.research.ed.ac.uk/portal/files/70005023/citysounds_overview_v1.3.pdf) for the [CitySounds] project
- Helped build a Norwegian speech synthesis voice for [Cereproc]
- TA for [Automatic Speech Recognition] and [Machine Learning Practical]
- Theatre consultant for [Charcoalblue], advising on audiovisual and acoustics design
- Software tester and mechanic for the stage technology company [Visual act]
- MSc Artificial Intelligence, [University of Edinburgh] 
- BMus Music & Sound Recording (Tonmeister), [IoSR], [University of Surrey]
- Various modules: calculus, linear algebra, electromagnetism and psychology, [University of Oslo]

### Publications
- P. Bell, J. Fainberg, O. Klejch, J. Li, S. Renals, P. Swietojanski, ["Adaptation Algorithms for Speech Recognition: An Overview"](https://arxiv.org/pdf/2008.06580.pdf), Submitted to IEEE Open Journal of Signal Processing 2020
- J. Fainberg, O. Klejch, E. Loweimi, P. Bell, S. Renals, ["Acoustic model adaptation from raw waveforms with SincNet"](http://arxiv.org/abs/1909.13759) [[Code](https://github.com/jfainberg/sincnet_adapt)], ASRU 2019
- O. Klejch, J. Fainberg, P. Bell, S. Renals, ["Speaker adaptive training using model agnostic meta-learning"](https://arxiv.org/abs/1910.10605) [[Code](https://github.com/ondrejklejch/learning_to_adapt)], ASRU 2019
- J. Fainberg, O. Klejch, S. Renals, P. Bell, ["Lattice-based lightly-supervised acoustic model training"](https://arxiv.org/pdf/1905.13150.pdf) [[Code](https://github.com/jfainberg/lattice_combination)], Interspeech 2019
- O. Klejch, J. Fainberg, P. Bell, S. Renals, ["Lattice-Based Unsupervised Test-Time Adaptation of Neural Network Acoustic Models"](https://arxiv.org/pdf/1906.11521.pdf), arXiv:1906.11521, 2019
- J. Fainberg, B. Krause, M. Dobre, M. Damonte, E. Kahembwe, D. Duma, B. Webber, F. Fancellu, ["Talking to myself: self-dialogues as data for conversational agents"](https://arxiv.org/pdf/1809.06641.pdf) [[Data](https://github.com/jfainberg/self_dialogue_corpus)], arXiv:1809.06641, 2018
- E. Klein, S. Chapple, J. Fainberg, C. Magill, M. Parker, C. Raab, J. Silvertown, ["Capturing the sounds of an urban greenspace"](https://www.research.ed.ac.uk/portal/files/70005023/citysounds_overview_v1.3.pdf), Smart Data and Smart Cities 2018
- O. Klejch, J. Fainberg, P. Bell, ["Learning to adapt: a meta-learning approach for speaker adaptation"](https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1244.pdf) [[Code](https://github.com/ondrejklejch/learning_to_adapt)], Interspeech 2018
- B. Krause, M. Damonte, M. Dobre, D. Duma, J. Fainberg, F. Fancellu, E. Kahembwe, J. Cheng, B. Webber, ["Edina: Building an Open Domain Socialbot with
Self-dialogues"](https://arxiv.org/pdf/1709.09816.pdf) [[Data](https://github.com/jfainberg/self_dialogue_corpus)]
, Proc. Alexa Prize 2017
- J. Fainberg, S. Renals, P. Bell, ["Factorised representations for neural network adaptation to diverse acoustic environments"](http://www.research.ed.ac.uk/portal/files/39658781/joachimIS2017.pdf), Interspeech 2017
- P. Bell, J. Fainberg, C. Lai, M. Sinclair, ["A system for real time collaborative transcription correction"](http://www.research.ed.ac.uk/portal/files/39291622/is2017demo_nh_1.pdf), Interspeech 2017
- J. Fainberg, P. Bell, M. Lincoln and S. Renals, ["Improving children's speech recognition through out-of-domain data augmentation"](http://www.cstr.ed.ac.uk/downloads/publications/2016/master.pdf), Interspeech 2016

### Patents
- N. D'Amato, D. Giacobello, J. Fainberg, K. Hartung, "Multiple Stage Network Microphone Device with Reduced Power Consumption and Processing Load", 2020
- J. Fainberg, D. Giacobello, K. Hartung, "Systems and Methods for Selective Wake Word Detection Using Neural Networks Models", 2020

{% comment %}
- C. Hummersone, J. Fainberg, and M. Dewhirst, "Binaural Computational Auditory Scene Analysis in Reverberant Environments Using a Histographic Localisation Algorithm", *IEEE Transactions on Acoustics, Speech and Signal Processing* (In review), 2015
{% endcomment %}

### Theses

- J. Fainberg, "Improving Children's Speech Recognition through Out of Domain Data Augmentation", *MSc thesis*, University of Edinburgh, Edinburgh, 2015
- J. Fainberg, "Sound Source Separation in Reverberant Environments using Interaural Coherence in a Probabilistic Model of Localisation", *BMus thesis* ([Poster](../soundsource_poster.pdf)), University of Surrey, Guildford, 2014

### Hobbies
- [Current Spotify playlist](https://open.spotify.com/playlist/4r6lFJOBHyutziAGhaqke9?si=pxVxWwOESNGZHqoTfQwXxw)
- [Chaos and fractals](/chaos)
- [Soundcloud](https://soundcloud.com/jodles-1)

[University of Edinburgh]: http://www.ed.ac.uk
[University of Surrey]: http://www.surrey.ac.uk
[University of Oslo]: http://www.uio.no
[IoSR]: http://iosr.surrey.ac.uk
[School of Informatics]: http://www.ed.ac.uk/informatics/
[CSTR]: http://www.cstr.ed.ac.uk
[ILCC]: http://www.ilcc.inf.ed.ac.uk
[Steve Renals]: http://homepages.inf.ed.ac.uk/srenals/
[Peter Bell]: http://homepages.inf.ed.ac.uk/pbell1/
[Charcoalblue]: http://www.charcoalblue.com
[Visual act]: http://visualact.net
[Daniele Giacobello]:https://sites.google.com/site/giacobello/
[Sonos]:http://www.sonos.com
[Bloomberg]:http://www.bloomberg.net
[CitySounds]:https://citysounds.eu
[Edina]:https://developer.amazon.com/alexaprize/challenges/past-challenges/2017/edina
[Amazon Alexa Prize]:https://developer.amazon.com/alexaprize
[Self-dialogue Corpus]:https://github.com/jfainberg/self_dialogue_corpus
[Cereproc]:https://www.cereproc.com
[Automatic Speech Recognition]:http://www.inf.ed.ac.uk/teaching/courses/asr/index-2019.html
[Machine Learning Practical]:http://www.inf.ed.ac.uk/teaching/courses/mlp/index-2018.html
[Machine Learning Center of Excellence]:https://www.jpmorgan.com/insights/technology/applied-ai-and-ml
